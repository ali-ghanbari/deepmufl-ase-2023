31880720,"	Batch 0 layer 6: Numerical Error in delta Weights, terminating training		 --- 14.605481999999999 seconds ---		 Please change the loss function 	 OR Please change the activaton function at layer: 7 	"
33969059,"	Batch 0: Invalid accuracy, terminating training		 --- 41.84126 seconds ---		 Learning Rate 	"
34311586,"	Batch 0 layer 2: Numerical Error in delta Weights, terminating training		 --- 0.8042829999999999 seconds ---	"
34673164,"N/A"
41596619,"	Batch 0: Invalid accuracy, terminating training		 --- 1.002383 seconds ---	 	 Please change the activation function at layer : 1 	"
41823068,"	Batch 0 layer 3:  Out of Rang Problem, terminating training		 --- 1.2498680000000002 seconds ---	 	 change the activation function to softmax 	"
41999686,"	Batch 0 layer 10:  Out of Rang Problem, terminating training		 --- 3.0706899999999995 seconds ---	 	 change the activation function to softmax 	"
42472447,"	Batch 0 layer 4:  Out of Rang Problem, terminating training		 --- 1.8518380000000003 seconds ---	 	 change the activation function to softmax 	"
43055289,"N/A"
46359741,"	Batch 0: Invalid accuracy, terminating training		 --- 1.041436 seconds ---	 	 Please change the activation function at layer : 1 	"
47704695,"N/A"
47735201,"N/A"
48221692,"	Batch 0: Invalid accuracy, terminating training		 --- 0.609248 seconds ---	 	 Please change the activation function at layer : 1 	"
48251943,"N/A"
48385830,"	 Batch 0 layer 0: Numerical Problem Forward, terminating training 		 --- 6.449567 seconds ---		Please change the activaton function at layer: 1	"
48486598,"N/A"
48976413,"	Batch 0: Invalid accuracy, terminating training		 --- 1.4280820000000003 seconds ---	 	 Please change the activation function at layer : 2 	"
50306988,"	Batch 0 layer 1:  Out of Rang Problem, terminating training		 --- 0.9832379999999998 seconds ---	 	 change the activation function to softmax 	"
50338865,"N/A"
50555434,"N/A"
50914860,"	Batch 0 layer 6:  Out of Rang Problem, terminating training		 --- 22.847368 seconds ---	 	 change the activation function to softmax 	"
51185079,"N/A"
51581521,"N/A"
51749207,"N/A"
51930566,"	Batch 0 layer 1:  Out of Rang Problem, terminating training		 --- 1.056373 seconds ---	 	 change the activation function to softmax 	"
52566823,"N/A"
52983831,"N/A"
53700537,"N/A"
53749895,"	Batch 0 layer 2: Numerical Error in delta Weights, terminating training		 --- 2.9597510000000007 seconds ---	"
54064299,"	 Batch 7 layer 7: Numerical Problem Forward, terminating training 		 --- 123.808556 seconds ---		 Normalize the data 	"
54738769,"	Batch 0 layer 6: Numerical Error in delta Weights, terminating training		 --- 1.556526 seconds ---	"
54811239,"N/A"
55198221,"	Batch 0 layer 8:  Out of Rang Problem, terminating training		 --- 2.133635 seconds ---	 	 change the activation function to softmax 	"
55328966,"	Batch 0 layer 2:  Out of Rang Problem, terminating training		 --- 3.903049000000001 seconds ---	 	 change the activation function to softmax 	"
58043002,"N/A"
58051767,"N/A"
58055105,"	Batch 0 layer 2: Numerical Error in delta Weights, terminating training		 --- 1.251982 seconds ---	"
58064701,"N/A"
58333926,"N/A"
58572274,"N/A"
56317174,"N/A"
56452176,"	 Batch 0 layer 0: Numerical Problem Forward, terminating training 		 --- 0.82094 seconds ---		 Normalize the data 	"
56774954,"	Batch 21 layer 2: Numerical Error in delta Weights, terminating training		 --- 10.658429 seconds ---	"
57326611,"	Batch 0 layer 1: Numerical Error in delta Weights, terminating training		 --- 4.554812 seconds ---	"
57397440,"N/A"
57407973,"	Batch 0 layer 9: Numerical Error in delta Weights, terminating training		 --- 2.624379 seconds ---	"
57516678,"N/A"
57943425,"N/A"
59278771,"	Batch 0 layer 1:  Out of Rang Problem, terminating training		 --- 0.7121120000000001 seconds ---	 	 change the activation function to softmax 	"
59758722,"N/A"
60355380,"	Batch 0 layer 13: Numerical Error in delta Weights, terminating training		 --- 3.3715780000000004 seconds ---	"
60574843,"N/A"
60766775,"N/A"
60831731,"N/A"
60874661,"N/A"
61234347,"	Batch 0 layer 7:  Out of Rang Problem, terminating training		 --- 1.9175740000000001 seconds ---	 	 change the activation function to softmax 	"
61274792,"N/A"
61498304,"	Batch 0 layer 13:  Out of Rang Problem, terminating training		 --- 3.8019730000000003 seconds ---	 	 change the activation function to softmax 	"
61763616,"N/A"
61886777,"N/A"
62068109,"	Batch 0 layer 14:  Out of Rang Problem, terminating training		 --- 5.519011000000001 seconds ---	 	 change the activation function to softmax 	"
62313327,"N/A"
62957334,"N/A"
44164749,"	Batch 0 layer 4:  Out of Rang Problem, terminating training		 --- 1.7540039999999997 seconds ---	 	 change the activation function to softmax 	"
44755431,"	Batch 4 layer 1: Dead Node Problem, terminating training		 --- 2867.44852 seconds ---		 Learning Rate 	"
44758894,"N/A"
45378493,"N/A"
45442843,"	Batch 0 layer 2: Vanishing Gradient Problem in delta Weights, terminating training		 --- 0.7441659999999999 seconds ---		 Learning Rate 	"
49583466,"N/A"
65669308,"N/A"
65777704,"N/A"
68101077,"	Batch 0 layer 2:  Out of Rang Problem, terminating training		 --- 27.198214999999998 seconds ---	 	 change the activation function to softmax 	"
68458462,"	Batch 39: Accurcy Not Increasing, terminating training		 --- 20.868883 seconds ---		 Normalize the data 	"
68751439,"	Batch 0 layer 3: Numerical Error in delta Weights, terminating training		 --- 1.413749 seconds ---	"
68773774,"	Batch 0 layer 3: Numerical Error in delta Weights, terminating training		 --- 5.806544 seconds ---	"
68938619,"N/A"
69787272,"N/A"
69901379,"N/A"
70589997,"	Batch 0 layer 9: Numerical Error in delta Weights, terminating training		 --- 5.051926 seconds ---	"
70650848,"N/A"
46247619,"	Batch 194 layer 1: Unchange Tensor in forward, terminating training		 --- 1378.245545 seconds ---	 	 Learning Rate 	"
46869312,"	Batch 1: Invalid accuracy, terminating training		 --- 4.173831 seconds ---	 	 Please change the activation function at layer : 2 	"
47241622,"N/A"
51901386,"	Batch 0 layer 15:  Out of Rang Problem, terminating training		 --- 63.110978 seconds ---	 	 change the activation function to softmax 	"
54282951,"	Batch 0 layer 4:  Out of Rang Problem, terminating training		 --- 11.164902999999999 seconds ---	 	 change the activation function to softmax 	"
56218256,"	Batch 0 layer 3: Numerical Error in delta Weights, terminating training		 --- 3.797144 seconds ---	"
56888491,"N/A"
64395424,"	Batch 2 layer 2: Numerical Error in delta Weights, terminating training		 --- 2.054542 seconds ---	"
64413907,"N/A"
66087653,"	Batch 0 layer 5: Numerical Error in delta Weights, terminating training		 --- 14.166608 seconds ---	"
58392266,"N/A"
58844149,"	Batch 0 layer 9: Numerical Error in delta Weights, terminating training		 --- 4.168527 seconds ---		 Please change the loss function 	 OR Please change the activaton function at layer: 10 	"
59078187,"N/A"
60508218,"N/A"
60801900,"N/A"
61997645,"N/A"
62055783,"	Batch 0 layer 10:  Out of Rang Problem, terminating training		 --- 14.347468999999998 seconds ---	 	 change the activation function to softmax 	"
66235657,"	Batch 0 layer 9:  Out of Rang Problem, terminating training		 --- 88.783123 seconds ---	 	 change the activation function to softmax 	"
66407123,"	Batch 0 layer 2: Numerical Error in delta Weights, terminating training		 --- 0.9097850000000001 seconds ---	"
66602662,"	Batch 7 layer 5: Vanishing Gradient Problem in delta Weights, terminating training		 --- 8.206988 seconds ---		 Learning Rate 	"
66840108,"	Batch 0: Invalid accuracy, terminating training		 --- 1.155356 seconds ---	 	 Please change the activation function at layer : 2 	"
62440336,"N/A"
63212385,"N/A"
64237179,"N/A"
64387251,"	Batch 4 layer 0: Unchange Tensor in forward, terminating training		 --- 83.09220300000001 seconds ---	 	 Learning Rate 	"
67529687,"	Batch 1 layer 18: Vanishing Gradient Problem in delta Weights, terminating training		 --- 81.776972 seconds ---		 Learning Rate 	"
68321264,"	Batch 0 layer 8: Numerical Error in delta Weights, terminating training		 --- 7.546325999999999 seconds ---		 Please change the loss function 	 OR Please change the activaton function at layer: 9 	"
68701979,"	Batch 0 layer 1:  Out of Rang Problem, terminating training		 --- 0.7121039999999998 seconds ---	 	 change the activation function to softmax 	"
70148149,"	Batch 0 layer 6: Numerical Error in delta Weights, terminating training		 --- 36.144161999999994 seconds ---	"
